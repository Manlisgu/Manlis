import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import pygwalker as pyg

from langchain.memory import ConversationBufferMemory
from csv_utils import dataframe_agent
from csv_classify_utils import classify_agent
from pdf_utils import qa_agent
from chatgpt_utils import get_chat_response

import base64
from wordfreq_utils import generate_wordcloud
import matplotlib.pyplot as plt # å›¾åƒå±•ç¤ºåº“ï¼Œä»¥ä¾¿åœ¨notebookä¸­æ˜¾ç¤ºå›¾ç‰‡


# é¡µé¢é…ç½®
st.set_page_config(page_title="AutoDataAnalyzer", layout="wide")

# åº”ç”¨æ ‡é¢˜
st.title("AutoDataAnalyzer - AIå¤§æ•°æ®åˆ†æä¸å¯è§†åŒ–")

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("å¯¼èˆª")
app_mode = st.sidebar.selectbox("é€‰æ‹©é¡µé¢", ["AIè½¦è¾†æ€§èƒ½å¤§æ•°æ®åˆ†æ", "AIæ™ºèƒ½CSVæ•°æ®åˆ†æå·¥å…·", "AIæ™ºèƒ½PDFé—®ç­”å·¥å…·", "AIæ™ºèƒ½å¯¹è¯é—®ç­”å·¥å…·", "é‡ç‚¹è®®é¢˜ç®¡ç†"
    #, "é—®é¢˜ç®¡ç†", "æŠ¥å‘Šç”Ÿæˆ"
                                             ])

def sidebar_bg(side_bg):
    side_bg_ext = 'png'
    st.markdown(
        f"""
        <style>
        [data-testid="stSidebar"] > div:first-child {{
            background: url(data:image/{side_bg_ext};base64,{base64.b64encode(open(side_bg, "rb").read()).decode()});
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )
# è°ƒç”¨
sidebar_bg('./pics/siderbackground2.jpg')

def background_bg(main_bg):
    main_bg_ext = "png"
    st.markdown(
        f"""
        <style>
        .stApp {{
            background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, "rb").read()).decode()});
            background-size: cover
        }}
        </style>
        """,
        unsafe_allow_html=True
    )
# è°ƒç”¨
background_bg('./pics/background.jpg')

with st.sidebar:
    openai_api_model = st.text_input("è¯·è¾“å…¥ChatAI Modelï¼š", type="password")
    st.markdown("[è·å–OpenAI Model: gpt-3.5-turbo(é»˜è®¤ï¼Œéœ€è¦é­”æ³•)]()")
    st.markdown("[æŸ¥é˜…Qwen Model: qwen-plus(é»˜è®¤)](https://help.aliyun.com/zh/dashscope/developer-reference/tongyi-thousand-questions-metering-and-billing?spm=a2c4g.11186623.help-menu-610100.d_3_5.72785120xkOrE4&scm=20140722.H_2399482._.OR_help-T_cn-DAS-zh-V_1)")
    #st.markdown("[é»˜è®¤kiMi Model: moonshot-v1-8k(é»˜è®¤)](https://www.volcengine.com/docs/82379/1099320)")
    st.markdown("[é»˜è®¤doubao Model: doubao-pro-32k(é»˜è®¤)](https://www.volcengine.com/docs/82379/1099320)")
    openai_api_key = st.text_input("è¯·è¾“å…¥ChatAI APIå¯†é’¥ï¼š", type="password")
    st.markdown("[è·å–OpenAI API key(éœ€è¦é­”æ³•)](https://platform.openai.com/account/api-keys)")
    st.markdown("[è·å–Qwen API key](https://bailian.console.aliyun.com/?apiKey=1#/api-key)")
    #st.markdown("[è·å–kiMi API key](https://platform.moonshot.cn/console/api-keys)")
    st.markdown("[è·å–doubao API key](https://console.volcengine.com/ark/region:ark+cn-beijing/apiKey?apikey=%7B%7D&projectName=undefined)")

def csv_main():
    st.header("ğŸ’¡ AIæ™ºèƒ½CSVæ•°æ®åˆ†æå·¥å…·")
    data = st.file_uploader("ä¸Šä¼ ä½ çš„æ•°æ®æ–‡ä»¶ï¼ˆCSVæ ¼å¼ï¼‰ï¼š", type="csv")
    if data:
        st.session_state["df"] = pd.read_csv(data)
        with st.expander("åŸå§‹æ•°æ®"):
            st.dataframe(st.session_state["df"])
    query = st.text_area("è¯·è¾“å…¥ä½ å…³äºä»¥ä¸Šè¡¨æ ¼çš„é—®é¢˜ï¼Œæˆ–æ•°æ®æå–è¯·æ±‚ï¼Œæˆ–å¯è§†åŒ–è¦æ±‚ï¼ˆæ”¯æŒæ•£ç‚¹å›¾ã€æŠ˜çº¿å›¾ã€æ¡å½¢å›¾ï¼‰ï¼š")
    button = st.button("ç”Ÿæˆå›ç­”")
    def create_chart(input_data, chart_type):
        df_data = pd.DataFrame(input_data["data"], columns=input_data["columns"])
        df_data.set_index(input_data["columns"][0], inplace=True)
        if chart_type == "bar":
            st.bar_chart(df_data)
        elif chart_type == "line":
            st.line_chart(df_data)
        elif chart_type == "scatter":
            st.scatter_chart(df_data)
    if button and not openai_api_model:
        st.info("è¯·è¾“å…¥ä½ çš„ChatAI Model")
    if button and not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„ChatAI APIå¯†é’¥")
    if button and "df" not in st.session_state:
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
    if button and openai_api_model and openai_api_key and "df" in st.session_state:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response_dict = dataframe_agent(openai_api_model, openai_api_key, st.session_state["df"], query)
            if "answer" in response_dict:
                st.write(response_dict["answer"])
            if "table" in response_dict:
                st.table(pd.DataFrame(response_dict["table"]["data"],
                                      columns=response_dict["table"]["columns"]))
            if "bar" in response_dict:
                create_chart(response_dict["bar"], "bar")
            if "line" in response_dict:
                create_chart(response_dict["line"], "line")
            if "scatter" in response_dict:
                create_chart(response_dict["scatter"], "scatter")

def pdf_main():
    st.header("ğŸ“‘ AIæ™ºèƒ½PDFé—®ç­”å·¥å…·")
    if "memory" not in st.session_state:
        st.session_state["memory"] = ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history",
            output_key="answer"
        )
    uploaded_file = st.file_uploader("ä¸Šä¼ ä½ çš„PDFæ–‡ä»¶ï¼š", type="pdf")
    question = st.text_input("å¯¹PDFçš„å†…å®¹è¿›è¡Œæé—®", disabled=not uploaded_file)
    if uploaded_file and question and not openai_api_model:
        st.info("è¯·è¾“å…¥ä½ çš„ChatAI Model")
    if uploaded_file and question and not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„ChatAI APIå¯†é’¥")
    if uploaded_file and question and openai_api_model and openai_api_key:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response = qa_agent(openai_api_model, openai_api_key, st.session_state["memory"],
                                uploaded_file, question)
        st.write("### ç­”æ¡ˆ")
        st.write(response["answer"])
        st.session_state["chat_history"] = response["chat_history"]
    if "chat_history" in st.session_state:
        with st.expander("å†å²æ¶ˆæ¯"):
            for i in range(0, len(st.session_state["chat_history"]), 2):
                human_message = st.session_state["chat_history"][i]
                ai_message = st.session_state["chat_history"][i + 1]
                st.write(human_message.content)
                st.write(ai_message.content)
                if i < len(st.session_state["chat_history"]) - 2:
                    st.divider()

def chatgpt_main():
    st.header("ğŸ’¬ AIæ™ºèƒ½å¯¹è¯é—®ç­”å·¥å…·")
    if "memory" not in st.session_state:
        st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
        st.session_state["messages"] = [{"role": "ai",
                                         "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]
    for message in st.session_state["messages"]:
        st.chat_message(message["role"]).write(message["content"])
    prompt = st.chat_input()
    if prompt:
        if not openai_api_model:
            st.info("è¯·è¾“å…¥ä½ çš„ChatAI Model")
            st.stop()
        if not openai_api_key:
            st.info("è¯·è¾“å…¥ä½ çš„ChatAI API Key")
            st.stop()
        st.session_state["messages"].append({"role": "human", "content": prompt})
        st.chat_message("human").write(prompt)
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response = get_chat_response(openai_api_model, openai_api_key,
                                         prompt, st.session_state["memory"])
        msg = {"role": "ai", "content": response}
        st.session_state["messages"].append(msg)
        st.chat_message("ai").write(response)


def analyze_performance():
    st.header("ğŸ“Š AIè½¦è¾†æ€§èƒ½å¤§æ•°æ®åˆ†æ")
    data_files = st.file_uploader("ä¸Šä¼ è½¦è¾†æ€§èƒ½æ•°æ®æ–‡ä»¶ï¼ˆCSVæ ¼å¼ï¼‰", type=["csv"], accept_multiple_files=True)
    if data_files:
        for uploaded_file in data_files:
            try:
                st.session_state["df"] = pd.read_csv(uploaded_file)
                st.subheader(f"æ•°æ®é¢„è§ˆ - {uploaded_file.name}")
                with st.expander("åŸå§‹æ•°æ®"):
                    st.dataframe(st.session_state["df"])
                st.subheader("æ•…éšœæ¸…å• - æ•…éšœæè¿°åˆ†ç±»")
                text_input = st.text_input("å°†éœ€è¦åˆ†ç±»çš„åˆ—ï¼ŒæŒ‰ç…§æ ¼å¼å¡«å†™å…³é”®è¯ã€‚å­—æ®µåï¼šå¼‚å“|æ¼æ°´|æ²¹æ¼†|...")
                button = st.button("ç”Ÿæˆåˆ†ç±»")
                if not button and not text_input:
                    # ä½¿ç”¨PyGWalkerè¿›è¡Œå¯è§†åŒ–
                    st.subheader("æ•°æ®å¯è§†åŒ–")
                    # pyg.walk(data)
                    # ä½¿ç”¨PyGWalkerç”ŸæˆHTML
                    pyg_html = pyg.to_html(st.session_state["df"])
                    # å°†HTMLåµŒå…¥åˆ°Streamlitåº”ç”¨ç¨‹åºä¸­
                    components.html(pyg_html, height=1000, scrolling=True)
                elif button and not text_input:
                    st.info("è¯·å…ˆè¾“å…¥åˆ†ç±»éœ€æ±‚")
                elif button and text_input:
                    if not openai_api_model:
                        st.info("è¯·è¾“å…¥ä½ çš„ChatAI Model")
                    elif not openai_api_key:
                        st.info("è¯·è¾“å…¥ä½ çš„ChatAI APIå¯†é’¥")
                    elif "df" not in st.session_state:
                        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
                    elif openai_api_model and openai_api_key and "df" in st.session_state:
                        text_list = text_input.split('ï¼š')
                        df_data = pd.DataFrame(st.session_state["df"])
                        question_list = list(df_data[text_list[0].strip()])
                        categories_list = [item.strip() for item in text_list[1].split('|')]
                        if question_list and categories_list:
                            with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
                                response_list = []
                                for q in question_list:
                                    response = classify_agent(openai_api_model, openai_api_key, categories_list, q)
                                    response_list += [response]
                                df_data.loc[:,"Classify"] = response_list
                                # ä½¿ç”¨imageè¿›è¡Œè¯äº‘å¯è§†åŒ–
                                st.subheader("åˆ†ç±»è¯äº‘")
                                with st.expander("ä¸‹é¢æ˜¯æ ¹æ®åˆ†ç±»æ•°æ®å’Œè‡ªå®šä¹‰èƒŒæ™¯å›¾ç”Ÿæˆçš„è¯äº‘ï¼š"):
                                    wordcloud = generate_wordcloud(df_data["Classify"])
                                    plt.figure(figsize=(10, 5))
                                    plt.imshow(wordcloud, interpolation='bilinear')
                                    plt.axis('off')  # ä¸æ˜¾ç¤ºåæ ‡è½´
                                    st.pyplot(plt)
                                st.subheader("åˆ†ç±»æ•°æ®é¢„è§ˆ")
                                with st.expander("ç±»åˆ«æ•°æ®"):
                                    st.dataframe(df_data)
                                # ä½¿ç”¨PyGWalkerè¿›è¡Œå¯è§†åŒ–
                                st.subheader("æ•°æ®å¯è§†åŒ–")
                                # pyg.walk(df_data)
                                # ä½¿ç”¨PyGWalkerç”ŸæˆHTML
                                pyg_html = pyg.to_html(df_data)
                                # å°†HTMLåµŒå…¥åˆ°Streamlitåº”ç”¨ç¨‹åºä¸­
                                components.html(pyg_html, height=1000, scrolling=True)
                        else:
                            st.info("è¯·æ­£ç¡®è¾“å…¥åˆ†ç±»éœ€æ±‚")
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ {uploaded_file.name} å¤±è´¥ï¼š{e}")


def manage_keyissues():
    st.header("ğŸ“â€ é‡ç‚¹è®®é¢˜ç®¡ç†å¹³å°")
    st.subheader("1ï¸âƒ£ï¸ è®®é¢˜åˆ›å»ºæäº¤")
    # é—®é¢˜åˆ—è¡¨
    # audio_url = "https://www.example.com/audio.mp3"
    # st.audio(audio_url)
    # video_url = "https://www.example.com/video.mp4"
    # st.video(video_url, start_time=0)
    url = "https://forms.office.com/pages/responsepage.aspx?id=RKcqmrK53U-tlatSW_OXlkaV6-0kIfVIiZjfnst8pVJUOFQxUVdQV0k3WkM2UkNIVUFPTUhTNVdEMS4u&origin=lprLink&route=shorturl"
    components.iframe(url, width=1400, height=800)
    # ä¸»ç•Œé¢
    st.subheader("2ï¸âƒ£ è®®é¢˜æ‘˜è¦æ¦‚è§ˆ")
    # ç”¨æˆ·è¾“å…¥ CSV æ–‡ä»¶çš„ URL
    list_url = "https://forms.office.com/Pages/AnalysisPage.aspx?AnalyzerToken=NVXeNdjxe7TrNnMywwkSCP9lqAeAXoeu&id=RKcqmrK53U-tlatSW_OXlkaV6-0kIfVIiZjfnst8pVJUOFQxUVdQV0k3WkM2UkNIVUFPTUhTNVdEMS4u"
    components.iframe(list_url, width=1400, height=800)
    st.subheader("3ï¸âƒ£ è®®é¢˜ç¼–è¾‘ä¿®æ”¹")
    edit_url = "https://pbi1u-my.sharepoint.com/:x:/g/personal/guyizhe_pbi1u_onmicrosoft_com/EWoRjmTh3SNOmpnsME1uTHgBqH4OP7sUx3KThEhcly0uhg?e=OXUYeR"
    components.iframe(edit_url, width=1400, height=800)


# æ ¹æ®å¯¼èˆªé€‰æ‹©å±•ç¤ºä¸åŒé¡µé¢
if app_mode == "AIè½¦è¾†æ€§èƒ½å¤§æ•°æ®åˆ†æ":
    analyze_performance()
elif app_mode == "AIæ™ºèƒ½CSVæ•°æ®åˆ†æå·¥å…·":
    csv_main()
elif app_mode == "AIæ™ºèƒ½PDFé—®ç­”å·¥å…·":
    pdf_main()
elif app_mode == "AIæ™ºèƒ½å¯¹è¯é—®ç­”å·¥å…·":
    chatgpt_main()
elif app_mode == "é‡ç‚¹è®®é¢˜ç®¡ç†":
    manage_keyissues()
